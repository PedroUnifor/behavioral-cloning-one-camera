   parser = argparse.ArgumentParser(description='Behavioral Cloning Training Program')
    parser.add_argument('-d', help='data directory',        dest='data_dir',          type=str,   default='Data')
    parser.add_argument('-t', help='test size fraction',    dest='test_size',         type=float, default=0.2)
    parser.add_argument('-k', help='drop out probability',  dest='keep_prob',         type=float, default=0.5)
    parser.add_argument('-n', help='number of epochs',      dest='nb_epoch',          type=int,   default=30)
    parser.add_argument('-s', help='samples per epoch',     dest='samples_per_epoch', type=int,   default=20000)
    parser.add_argument('-b', help='batch size',            dest='batch_size',        type=int,   default=150)
    parser.add_argument('-o', help='save best models only', dest='save_best_only',    type=s2b,   default='True')
    parser.add_argument('-l', help='learning rate',         dest='learning_rate',     type=float, default=1.0e-3)



20100/20000 [==============================] - 423s - loss: 0.0736 - val_loss: 0.0473
Epoch 2/30
20100/20000 [==============================] - 420s - loss: 0.0670 - val_loss: 0.0450
Epoch 3/30
20100/20000 [==============================] - 416s - loss: 0.0686 - val_loss: 0.0389
Epoch 4/30
20100/20000 [==============================] - 421s - loss: 0.0705 - val_loss: 0.0458
Epoch 5/30
20100/20000 [==============================] - 418s - loss: 0.0718 - val_loss: 0.0527
Epoch 6/30
20100/20000 [==============================] - 418s - loss: 0.0751 - val_loss: 0.0483
Epoch 7/30
20100/20000 [==============================] - 417s - loss: 0.0780 - val_loss: 0.0543
Epoch 8/30
20100/20000 [==============================] - 417s - loss: 0.0787 - val_loss: 0.0604
Epoch 9/30
20100/20000 [==============================] - 420s - loss: 0.0825 - val_loss: 0.0529
Epoch 10/30
20100/20000 [==============================] - 418s - loss: 0.0795 - val_loss: 0.0579
Epoch 11/30
20100/20000 [==============================] - 419s - loss: 0.0848 - val_loss: 0.0618
Epoch 12/30
20100/20000 [==============================] - 418s - loss: 0.0858 - val_loss: 0.0497
Epoch 13/30
20100/20000 [==============================] - 417s - loss: 0.0851 - val_loss: 0.0670
Epoch 14/30
20100/20000 [==============================] - 416s - loss: 0.0895 - val_loss: 0.0621
Epoch 15/30
20100/20000 [==============================] - 419s - loss: 0.0899 - val_loss: 0.0830
Epoch 16/30
20100/20000 [==============================] - 416s - loss: 0.0941 - val_loss: 0.0705
Epoch 17/30
20100/20000 [==============================] - 419s - loss: 0.0966 - val_loss: 0.0770
Epoch 18/30
20100/20000 [==============================] - 420s - loss: 0.0951 - val_loss: 0.0878
Epoch 19/30
20100/20000 [==============================] - 421s - loss: 0.1001 - val_loss: 0.0810
Epoch 20/30
20100/20000 [==============================] - 420s - loss: 0.1001 - val_loss: 0.0779
Epoch 21/30
20100/20000 [==============================] - 419s - loss: 0.1033 - val_loss: 0.1006
Epoch 22/30
20100/20000 [==============================] - 418s - loss: 0.1045 - val_loss: 0.0883
Epoch 23/30
20100/20000 [==============================] - 420s - loss: 0.1067 - val_loss: 0.1001
Epoch 24/30
20100/20000 [==============================] - 417s - loss: 0.1072 - val_loss: 0.1124
Epoch 25/30
20100/20000 [==============================] - 416s - loss: 0.1074 - val_loss: 0.1069
Epoch 26/30
20100/20000 [==============================] - 420s - loss: 0.1125 - val_loss: 0.1017
Epoch 27/30
20100/20000 [==============================] - 419s - loss: 0.1164 - val_loss: 0.1122
Epoch 28/30
20100/20000 [==============================] - 417s - loss: 0.1152 - val_loss: 0.1045
Epoch 29/30
20100/20000 [==============================] - 416s - loss: 0.1120 - val_loss: 0.1244
Epoch 30/30
20100/20000 [==============================] - 418s - loss: 0.1153 - val_loss: 0.1313

