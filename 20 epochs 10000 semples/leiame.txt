    parser = argparse.ArgumentParser(description='Behavioral Cloning Training Program')
    parser.add_argument('-d', help='data directory',        dest='data_dir',          type=str,   default='Data')
    parser.add_argument('-t', help='test size fraction',    dest='test_size',         type=float, default=0.2)
    parser.add_argument('-k', help='drop out probability',  dest='keep_prob',         type=float, default=0.5)
    parser.add_argument('-n', help='number of epochs',      dest='nb_epoch',          type=int,   default=20)
    parser.add_argument('-s', help='samples per epoch',     dest='samples_per_epoch', type=int,   default=10000)
    parser.add_argument('-b', help='batch size',            dest='batch_size',        type=int,   default=150)
    parser.add_argument('-o', help='save best models only', dest='save_best_only',    type=s2b,   default='True')
    parser.add_argument('-l', help='learning rate',         dest='learning_rate',     type=float, default=1.0e-3)


10050/10000 [==============================] - 236s - loss: 0.0786 - val_loss: 0.0396
Epoch 2/20
10050/10000 [==============================] - 216s - loss: 0.0736 - val_loss: 0.0412
Epoch 3/20
10050/10000 [==============================] - 211s - loss: 0.0686 - val_loss: 0.0392
Epoch 4/20
10050/10000 [==============================] - 209s - loss: 0.0697 - val_loss: 0.0330
Epoch 5/20
10050/10000 [==============================] - 212s - loss: 0.0707 - val_loss: 0.0371
Epoch 6/20
10050/10000 [==============================] - 211s - loss: 0.0712 - val_loss: 0.0406
Epoch 7/20
10050/10000 [==============================] - 212s - loss: 0.0757 - val_loss: 0.0430
Epoch 8/20
10050/10000 [==============================] - 210s - loss: 0.0752 - val_loss: 0.0467
Epoch 9/20
10050/10000 [==============================] - 222s - loss: 0.0751 - val_loss: 0.0454
Epoch 10/20
10050/10000 [==============================] - 213s - loss: 0.0771 - val_loss: 0.0434
Epoch 11/20
10050/10000 [==============================] - 216s - loss: 0.0795 - val_loss: 0.0357
Epoch 12/20
10050/10000 [==============================] - 226s - loss: 0.0788 - val_loss: 0.0447
Epoch 13/20
10050/10000 [==============================] - 213s - loss: 0.0829 - val_loss: 0.0506
Epoch 14/20
10050/10000 [==============================] - 216s - loss: 0.0824 - val_loss: 0.0441
Epoch 15/20
10050/10000 [==============================] - 209s - loss: 0.0828 - val_loss: 0.0563
Epoch 16/20
10050/10000 [==============================] - 234s - loss: 0.0828 - val_loss: 0.0479
Epoch 17/20
10050/10000 [==============================] - 241s - loss: 0.0857 - val_loss: 0.0556
Epoch 18/20
10050/10000 [==============================] - 236s - loss: 0.0875 - val_loss: 0.0581
Epoch 19/20
10050/10000 [==============================] - 247s - loss: 0.0869 - val_loss: 0.0508
Epoch 20/20
10050/10000 [==============================] - 240s - loss: 0.0872 - val_loss: 0.0655





