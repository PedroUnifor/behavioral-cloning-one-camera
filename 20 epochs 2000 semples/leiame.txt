    parser = argparse.ArgumentParser(description='Behavioral Cloning Training Program')
    parser.add_argument('-d', help='data directory',        dest='data_dir',          type=str,   default='Data')
    parser.add_argument('-t', help='test size fraction',    dest='test_size',         type=float, default=0.2)
    parser.add_argument('-k', help='drop out probability',  dest='keep_prob',         type=float, default=0.5)
    parser.add_argument('-n', help='number of epochs',      dest='nb_epoch',          type=int,   default=20)
    parser.add_argument('-s', help='samples per epoch',     dest='samples_per_epoch', type=int,   default=2000)
    parser.add_argument('-b', help='batch size',            dest='batch_size',        type=int,   default=200)
    parser.add_argument('-o', help='save best models only', dest='save_best_only',    type=s2b,   default='True')
    parser.add_argument('-l', help='learning rate',         dest='learning_rate',     type=float, default=1.0e-3)




1800/2000 [==========================>...] - ETA: 5s - loss: 0.0896 221
2000/2000 [==============================] - 64s - loss: 0.0876 - val_loss: 0.0474
Epoch 2/20
2000/2000 [==============================] - 48s - loss: 0.0781 - val_loss: 0.0431
Epoch 3/20
2000/2000 [==============================] - 48s - loss: 0.0767 - val_loss: 0.0404
Epoch 4/20
2000/2000 [==============================] - 48s - loss: 0.0718 - val_loss: 0.0441
Epoch 5/20
2000/2000 [==============================] - 47s - loss: 0.0699 - val_loss: 0.0453
Epoch 6/20
2000/2000 [==============================] - 51s - loss: 0.0720 - val_loss: 0.0433
Epoch 7/20
2000/2000 [==============================] - 46s - loss: 0.0727 - val_loss: 0.0431
Epoch 8/20
2000/2000 [==============================] - 46s - loss: 0.0691 - val_loss: 0.0457
Epoch 9/20
2000/2000 [==============================] - 46s - loss: 0.0731 - val_loss: 0.0428
Epoch 10/20
2000/2000 [==============================] - 46s - loss: 0.0726 - val_loss: 0.0401
Epoch 11/20
2000/2000 [==============================] - 45s - loss: 0.0658 - val_loss: 0.0436
Epoch 12/20
2000/2000 [==============================] - 46s - loss: 0.0734 - val_loss: 0.0385
Epoch 13/20
2000/2000 [==============================] - 47s - loss: 0.0723 - val_loss: 0.0368
Epoch 14/20
2000/2000 [==============================] - 46s - loss: 0.0703 - val_loss: 0.0408
Epoch 15/20
2000/2000 [==============================] - 46s - loss: 0.0710 - val_loss: 0.0415
Epoch 16/20
2000/2000 [==============================] - 47s - loss: 0.0727 - val_loss: 0.0472
Epoch 17/20
2000/2000 [==============================] - 46s - loss: 0.0735 - val_loss: 0.0355
Epoch 18/20
2000/2000 [==============================] - 46s - loss: 0.0701 - val_loss: 0.0411
Epoch 19/20
2000/2000 [==============================] - 46s - loss: 0.0725 - val_loss: 0.0390
Epoch 20/20
2000/2000 [==============================] - 46s - loss: 0.0713 - val_loss: 0.0412

